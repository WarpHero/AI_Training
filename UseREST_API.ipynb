{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "dGSNSOUtK2h7"
      ],
      "authorship_tag": "ABX9TyPCPDTeVEW3VXny3FVX+cIs"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Colab with Flask"
      ],
      "metadata": {
        "id": "IXO_WYg7KudC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train MLP"
      ],
      "metadata": {
        "id": "UQ96F1pRtu9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "metadata": {
        "id": "pIWACoHfMz8p"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### preprocess data"
      ],
      "metadata": {
        "id": "ugTGtO1yuCFu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "X=pd.read_csv('X.csv')\n",
        "\n",
        "with open ('y.npy', 'rb') as f:\n",
        "  y=np.load(f)"
      ],
      "metadata": {
        "id": "WfNyclWTuBcm"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select features\n",
        "# 전부 다 쓰지 않고 8개만 선택\n",
        "X=X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]"
      ],
      "metadata": {
        "id": "xl8quodiuQbN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lG_H3NkBwhsd",
        "outputId": "b0c01393-2fdd-4a6e-8e6c-75fd3394374f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "scaled_y=y_min_max_scaler.transform(y)"
      ],
      "metadata": {
        "id": "oUQv54lVxRNj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X.shape, scaled_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvSuep4cxzdC",
        "outputId": "4016d534-8b96-4125-d31b-edd027eabb78"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1460, 8), (1460, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training"
      ],
      "metadata": {
        "id": "-AIe49wux_Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=scaled_X.shape[-1]),\n",
        "        layers.Dense(96, activation='relu'),\n",
        "        layers.Dense(48, activation='relu'),\n",
        "        layers.Dense(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "model.fit(scaled_X, scaled_y,\n",
        "          batch_size=2, epochs=150,\n",
        "          callbacks=[early_stopping_callback], validation_split=0.005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSb80KMfx3aC",
        "outputId": "60a14a6a-383f-4039-85a7-4aa68e9e27e0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "726/726 [==============================] - 3s 3ms/step - loss: 0.0043 - val_loss: 0.0016\n",
            "Epoch 2/150\n",
            "726/726 [==============================] - 3s 4ms/step - loss: 0.0031 - val_loss: 0.0018\n",
            "Epoch 3/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0033 - val_loss: 0.0032\n",
            "Epoch 4/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0030 - val_loss: 0.0014\n",
            "Epoch 5/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0011\n",
            "Epoch 6/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 7/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 8/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0024\n",
            "Epoch 9/150\n",
            "726/726 [==============================] - 3s 4ms/step - loss: 0.0025 - val_loss: 0.0010\n",
            "Epoch 10/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 11/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 12/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 13/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 14/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 15/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0029 - val_loss: 0.0014\n",
            "Epoch 16/150\n",
            "726/726 [==============================] - 3s 4ms/step - loss: 0.0021 - val_loss: 9.3062e-04\n",
            "Epoch 17/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 18/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0066\n",
            "Epoch 19/150\n",
            "726/726 [==============================] - 2s 3ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 20/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0020 - val_loss: 0.0029\n",
            "Epoch 21/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 22/150\n",
            "726/726 [==============================] - 2s 3ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 23/150\n",
            "726/726 [==============================] - 2s 3ms/step - loss: 0.0021 - val_loss: 0.0017\n",
            "Epoch 24/150\n",
            "726/726 [==============================] - 2s 3ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 25/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0022 - val_loss: 0.0015\n",
            "Epoch 26/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 27/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0019\n",
            "Epoch 28/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 29/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 30/150\n",
            "726/726 [==============================] - 3s 4ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 31/150\n",
            "726/726 [==============================] - 2s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f691265f8e0>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ5HO9MCy7XC",
        "outputId": "e90ac58a-c9cb-40d3-a4f0-78472e8654d9"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1460, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(scaled_X[:5])\n",
        "pred=y_min_max_scaler.inverse_transform(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqYX5LelzPWh",
        "outputId": "e03eab98-5e14-47ea-ee08-7e93626e8ab0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 121ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h328G5X2zbEq",
        "outputId": "3be704f1-0ca7-4199-854b-d40882c7133e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str(pred[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "49hVa1vtzdLC",
        "outputId": "475c262e-b859-48d6-b055-d9f4453fc17b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'185372.31'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7FBduYeezgjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save MLP model"
      ],
      "metadata": {
        "id": "oLZ3mkXx9kiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model 저장해서 쓰면 더 효율적\n",
        "# 학습 시킨 모델은 일반적으로 h5 파일로 저장함\n",
        "# H5 파일은 HDF (Hierarchical Data Format)로 저장된 데이터 파일\n",
        "model.save(\"mlp_v0.1.h5\")"
      ],
      "metadata": {
        "id": "H9clQYf39oku"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")"
      ],
      "metadata": {
        "id": "XY7f5gwB9xSH"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = reconstructed_model.predict(scaled_X[:1]) #0-1\n",
        "pred = y_min_max_scaler.inverse_transform(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndI4VT4D95q_",
        "outputId": "a7a38c41-7f21-4056-d376-540cf75de9e3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 72ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Vf5JiXr-OKG",
        "outputId": "656d5592-4e79-48a8-beb0-3d3c7a109929"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[185372.31]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## install Flask Ngrok"
      ],
      "metadata": {
        "id": "dGSNSOUtK2h7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3QCvkEhJ5u1",
        "outputId": "6790f10c-5e5e-4682-ac7a-06f97933af74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.8/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.8/dist-packages (from flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from flask-ngrok) (2.25.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.3)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (2.1.2)\n",
            "Requirement already satisfied: importlib-metadata>=3.6.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (6.0.0)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.8/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=3.6.0->Flask>=0.8->flask-ngrok) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask-ngrok) (2.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Flask Web Server 만들기"
      ],
      "metadata": {
        "id": "CIsx3Af1Kmlx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 아주 간단한 형태임"
      ],
      "metadata": {
        "id": "A6uNnn2CKskY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app=Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return \"<h1>This is your Flask server.</h1>\"\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hy6vN_SqKABG",
        "outputId": "8bbde152-926a-49be-ab26-c6f5a8330af4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://0291-34-80-93-56.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# 서버가 실행 될 때 X, y 데이터 가지고 있어야 좋다\n",
        "# load data\n",
        "X=pd.read_csv('X.csv')\n",
        "\n",
        "with open ('y.npy', 'rb') as f:\n",
        "  y=np.load(f)\n",
        "\n",
        "X=X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "# Min Max Scaler 하면 서버가 시작할 때 최대 최소값을 가지고 있게 됨\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "\n",
        "# load model\n",
        "reconstructed_model=keras.models.load_model(\"mlp_v0.1.h5\")\n",
        "\n",
        "\n",
        "# run Server\n",
        "app=Flask(__name__, template_folder='/content')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "def preprocess_data(data):\n",
        "  #TODO : preprocessing\n",
        "\n",
        "  # Dictionary --> np array (1, 8)\n",
        "\n",
        "  # Scale normalization\n",
        "\n",
        "  X=[]\n",
        "\n",
        "  for k, v in data.items():\n",
        "    if k=='LotShape':\n",
        "      if v=='Reg':\n",
        "        X.append(4)\n",
        "      elif v=='IR1':\n",
        "        X.append(3)\n",
        "      elif v=='IR2':\n",
        "        X.append(2)\n",
        "      elif v=='IR3':\n",
        "        x.append(1)\n",
        "      else:\n",
        "        x.append(float(v))\n",
        "  \n",
        "  # X= [value1, value2, value3, ... ]\n",
        "  X = np.array(X) # (8, )\n",
        "  X = X.reshape((1, -1)) # (1, 8)\n",
        "\n",
        "  # min_max scaling\n",
        "  scaled_X = x_min_max_scaler.transform(X)\n",
        "  # print(scaled_X.shape)\n",
        "\n",
        "  return scaled_X \n",
        "\n",
        "\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return \"<h1>This is your Flask server.</h1>\"\n",
        "\n",
        "@app.route(\"/predict\")\n",
        "def predict():\n",
        "  \n",
        "  return render_template(\"submit_form.html\") # html파일을 직접 띄울 수 있음\n",
        "\n",
        "@app.route(\"/result\", methods=[\"POST\"])\n",
        "def result():\n",
        "  # Read Data\n",
        "  # Preprocess Data\n",
        "  # Model Prediction\n",
        "  # Retrun Prediction\n",
        "  \n",
        "  data = request.form # request로 들어온 form 을 읽을 수 있음\n",
        "\n",
        "  message = \"\"\n",
        "  message += \"<h1>House Price.</h1>\"\n",
        "  \n",
        "  for k, v in data.items():\n",
        "    print(k, v)\n",
        "    message += k +\" : \"+v+\"</br>\"\n",
        "\n",
        "# data preprocessing\n",
        "  X=preprocess_data(data) # data : user가 보낸 것\n",
        "\n",
        "  # pred = model.predict(X) # X:(1, 8)\n",
        "  pred = reconstructed_model.predict(X) # 미리 훈련시켜 놓은 모델 저장해서 사용한다\n",
        "  pred = y_min_max_scaler.inverse_transform(pred) # pred: (1,1)\n",
        "\n",
        "  message+=\"</br>\"\n",
        "  message+=\"Predicted price: \"+str(pred[0][0]) # message로 보내기 위해서 str 변환\n",
        "\n",
        "  return message\n",
        "\n",
        "app.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIGXdqUnKIyD",
        "outputId": "04a1ac91-55a5-42ec-e3ca-229c2625066e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 필수 파일 X.csv, x.npy, y.npy, html 파일, 학습한 모델 파일만 있으면 플랫폼에 구애받지 않고 배포할 수 있다."
      ],
      "metadata": {
        "id": "AnCpVuro_NaN"
      }
    }
  ]
}